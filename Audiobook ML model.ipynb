{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b07570d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77c77e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2d/ljvkfh3j2592mkn7n0p8bd5h0000gn/T/ipykernel_43508/2112019824.py:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  train_inputs = npz['inputs'].astype(np.float)\n",
      "/var/folders/2d/ljvkfh3j2592mkn7n0p8bd5h0000gn/T/ipykernel_43508/2112019824.py:4: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  train_targets= npz['targets'].astype(np.int)\n",
      "/var/folders/2d/ljvkfh3j2592mkn7n0p8bd5h0000gn/T/ipykernel_43508/2112019824.py:7: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  validation_inputs, validation_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
      "/var/folders/2d/ljvkfh3j2592mkn7n0p8bd5h0000gn/T/ipykernel_43508/2112019824.py:7: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  validation_inputs, validation_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
      "/var/folders/2d/ljvkfh3j2592mkn7n0p8bd5h0000gn/T/ipykernel_43508/2112019824.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_inputs= npz['inputs'].astype(np.float)\n",
      "/var/folders/2d/ljvkfh3j2592mkn7n0p8bd5h0000gn/T/ipykernel_43508/2112019824.py:11: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_targets= npz['targets'].astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "npz = np.load('Audiobooks_data_train.npz')\n",
    "\n",
    "train_inputs = npz['inputs'].astype(np.float)\n",
    "train_targets= npz['targets'].astype(np.int)\n",
    "\n",
    "npz = np.load('Audiobooks_data_validation.npz')\n",
    "validation_inputs, validation_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
    "\n",
    "npz = np.load('Audiobooks_data_test.npz')\n",
    "test_inputs= npz['inputs'].astype(np.float)\n",
    "test_targets= npz['targets'].astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc0e69a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 12:00:59.452738: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 - 0s - loss: 0.6117 - accuracy: 0.6695 - val_loss: 0.5345 - val_accuracy: 0.7271 - 374ms/epoch - 10ms/step\n",
      "Epoch 2/100\n",
      "36/36 - 0s - loss: 0.4882 - accuracy: 0.7751 - val_loss: 0.4700 - val_accuracy: 0.7539 - 38ms/epoch - 1ms/step\n",
      "Epoch 3/100\n",
      "36/36 - 0s - loss: 0.4342 - accuracy: 0.7843 - val_loss: 0.4390 - val_accuracy: 0.7651 - 37ms/epoch - 1ms/step\n",
      "Epoch 4/100\n",
      "36/36 - 0s - loss: 0.4081 - accuracy: 0.7983 - val_loss: 0.4198 - val_accuracy: 0.7808 - 34ms/epoch - 945us/step\n",
      "Epoch 5/100\n",
      "36/36 - 0s - loss: 0.3919 - accuracy: 0.7994 - val_loss: 0.4234 - val_accuracy: 0.7740 - 36ms/epoch - 1ms/step\n",
      "Epoch 6/100\n",
      "36/36 - 0s - loss: 0.3837 - accuracy: 0.7999 - val_loss: 0.4022 - val_accuracy: 0.7830 - 37ms/epoch - 1ms/step\n",
      "Epoch 7/100\n",
      "36/36 - 0s - loss: 0.3760 - accuracy: 0.8080 - val_loss: 0.3997 - val_accuracy: 0.7740 - 37ms/epoch - 1ms/step\n",
      "Epoch 8/100\n",
      "36/36 - 0s - loss: 0.3742 - accuracy: 0.8061 - val_loss: 0.4170 - val_accuracy: 0.7718 - 42ms/epoch - 1ms/step\n",
      "Epoch 9/100\n",
      "36/36 - 0s - loss: 0.3674 - accuracy: 0.8094 - val_loss: 0.3912 - val_accuracy: 0.7875 - 58ms/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "36/36 - 0s - loss: 0.3634 - accuracy: 0.8136 - val_loss: 0.3870 - val_accuracy: 0.7919 - 41ms/epoch - 1ms/step\n",
      "Epoch 11/100\n",
      "36/36 - 0s - loss: 0.3627 - accuracy: 0.8089 - val_loss: 0.3872 - val_accuracy: 0.7852 - 38ms/epoch - 1ms/step\n",
      "Epoch 12/100\n",
      "36/36 - 0s - loss: 0.3614 - accuracy: 0.8103 - val_loss: 0.3906 - val_accuracy: 0.7808 - 42ms/epoch - 1ms/step\n",
      "Epoch 13/100\n",
      "36/36 - 0s - loss: 0.3582 - accuracy: 0.8108 - val_loss: 0.3811 - val_accuracy: 0.7942 - 37ms/epoch - 1ms/step\n",
      "Epoch 14/100\n",
      "36/36 - 0s - loss: 0.3562 - accuracy: 0.8148 - val_loss: 0.3966 - val_accuracy: 0.7919 - 37ms/epoch - 1ms/step\n",
      "Epoch 15/100\n",
      "36/36 - 0s - loss: 0.3589 - accuracy: 0.8083 - val_loss: 0.3946 - val_accuracy: 0.7852 - 37ms/epoch - 1ms/step\n",
      "Epoch 16/100\n",
      "36/36 - 0s - loss: 0.3568 - accuracy: 0.8044 - val_loss: 0.3829 - val_accuracy: 0.7785 - 36ms/epoch - 998us/step\n",
      "Epoch 17/100\n",
      "36/36 - 0s - loss: 0.3542 - accuracy: 0.8122 - val_loss: 0.3810 - val_accuracy: 0.7852 - 40ms/epoch - 1ms/step\n",
      "Epoch 18/100\n",
      "36/36 - 0s - loss: 0.3530 - accuracy: 0.8111 - val_loss: 0.3733 - val_accuracy: 0.7964 - 35ms/epoch - 962us/step\n",
      "Epoch 19/100\n",
      "36/36 - 0s - loss: 0.3505 - accuracy: 0.8139 - val_loss: 0.3723 - val_accuracy: 0.7942 - 37ms/epoch - 1ms/step\n",
      "Epoch 20/100\n",
      "36/36 - 0s - loss: 0.3523 - accuracy: 0.8131 - val_loss: 0.3755 - val_accuracy: 0.7875 - 36ms/epoch - 1ms/step\n",
      "Epoch 21/100\n",
      "36/36 - 0s - loss: 0.3503 - accuracy: 0.8114 - val_loss: 0.3794 - val_accuracy: 0.7875 - 37ms/epoch - 1ms/step\n",
      "Epoch 22/100\n",
      "36/36 - 0s - loss: 0.3504 - accuracy: 0.8145 - val_loss: 0.4058 - val_accuracy: 0.7852 - 35ms/epoch - 985us/step\n",
      "Epoch 23/100\n",
      "36/36 - 0s - loss: 0.3518 - accuracy: 0.8111 - val_loss: 0.3792 - val_accuracy: 0.7875 - 38ms/epoch - 1ms/step\n",
      "Epoch 24/100\n",
      "36/36 - 0s - loss: 0.3462 - accuracy: 0.8159 - val_loss: 0.3875 - val_accuracy: 0.7897 - 37ms/epoch - 1ms/step\n",
      "Epoch 25/100\n",
      "36/36 - 0s - loss: 0.3476 - accuracy: 0.8142 - val_loss: 0.3860 - val_accuracy: 0.7852 - 37ms/epoch - 1ms/step\n",
      "Epoch 26/100\n",
      "36/36 - 0s - loss: 0.3467 - accuracy: 0.8153 - val_loss: 0.3784 - val_accuracy: 0.7897 - 35ms/epoch - 983us/step\n",
      "Epoch 27/100\n",
      "36/36 - 0s - loss: 0.3450 - accuracy: 0.8184 - val_loss: 0.3672 - val_accuracy: 0.7942 - 39ms/epoch - 1ms/step\n",
      "Epoch 28/100\n",
      "36/36 - 0s - loss: 0.3438 - accuracy: 0.8164 - val_loss: 0.3739 - val_accuracy: 0.7919 - 36ms/epoch - 994us/step\n",
      "Epoch 29/100\n",
      "36/36 - 0s - loss: 0.3444 - accuracy: 0.8167 - val_loss: 0.3828 - val_accuracy: 0.7897 - 36ms/epoch - 997us/step\n",
      "Epoch 30/100\n",
      "36/36 - 0s - loss: 0.3447 - accuracy: 0.8150 - val_loss: 0.3670 - val_accuracy: 0.7919 - 36ms/epoch - 999us/step\n",
      "Epoch 31/100\n",
      "36/36 - 0s - loss: 0.3456 - accuracy: 0.8108 - val_loss: 0.3727 - val_accuracy: 0.7942 - 36ms/epoch - 990us/step\n",
      "Epoch 32/100\n",
      "36/36 - 0s - loss: 0.3416 - accuracy: 0.8167 - val_loss: 0.3761 - val_accuracy: 0.7897 - 36ms/epoch - 991us/step\n",
      "Epoch 33/100\n",
      "36/36 - 0s - loss: 0.3437 - accuracy: 0.8167 - val_loss: 0.3867 - val_accuracy: 0.7830 - 36ms/epoch - 990us/step\n",
      "Epoch 34/100\n",
      "36/36 - 0s - loss: 0.3456 - accuracy: 0.8120 - val_loss: 0.3707 - val_accuracy: 0.7919 - 37ms/epoch - 1ms/step\n",
      "Epoch 35/100\n",
      "36/36 - 0s - loss: 0.3429 - accuracy: 0.8181 - val_loss: 0.3749 - val_accuracy: 0.7919 - 37ms/epoch - 1ms/step\n",
      "Epoch 36/100\n",
      "36/36 - 0s - loss: 0.3419 - accuracy: 0.8181 - val_loss: 0.3630 - val_accuracy: 0.7897 - 36ms/epoch - 1ms/step\n",
      "Epoch 37/100\n",
      "36/36 - 0s - loss: 0.3448 - accuracy: 0.8159 - val_loss: 0.3832 - val_accuracy: 0.7919 - 36ms/epoch - 997us/step\n",
      "Epoch 38/100\n",
      "36/36 - 0s - loss: 0.3417 - accuracy: 0.8181 - val_loss: 0.3645 - val_accuracy: 0.7942 - 35ms/epoch - 963us/step\n",
      "Epoch 39/100\n",
      "36/36 - 0s - loss: 0.3433 - accuracy: 0.8159 - val_loss: 0.3674 - val_accuracy: 0.7875 - 40ms/epoch - 1ms/step\n",
      "Epoch 40/100\n",
      "36/36 - 0s - loss: 0.3401 - accuracy: 0.8156 - val_loss: 0.3891 - val_accuracy: 0.7763 - 54ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "36/36 - 0s - loss: 0.3459 - accuracy: 0.8184 - val_loss: 0.3644 - val_accuracy: 0.7987 - 36ms/epoch - 992us/step\n",
      "Epoch 42/100\n",
      "36/36 - 0s - loss: 0.3402 - accuracy: 0.8159 - val_loss: 0.3680 - val_accuracy: 0.7942 - 38ms/epoch - 1ms/step\n",
      "Epoch 43/100\n",
      "36/36 - 0s - loss: 0.3395 - accuracy: 0.8159 - val_loss: 0.3688 - val_accuracy: 0.7942 - 35ms/epoch - 959us/step\n",
      "Epoch 44/100\n",
      "36/36 - 0s - loss: 0.3394 - accuracy: 0.8234 - val_loss: 0.3930 - val_accuracy: 0.7852 - 35ms/epoch - 983us/step\n",
      "Epoch 45/100\n",
      "36/36 - 0s - loss: 0.3390 - accuracy: 0.8181 - val_loss: 0.3700 - val_accuracy: 0.7852 - 35ms/epoch - 973us/step\n",
      "Epoch 46/100\n",
      "36/36 - 0s - loss: 0.3388 - accuracy: 0.8209 - val_loss: 0.3698 - val_accuracy: 0.7919 - 35ms/epoch - 983us/step\n",
      "Epoch 47/100\n",
      "36/36 - 0s - loss: 0.3402 - accuracy: 0.8203 - val_loss: 0.3864 - val_accuracy: 0.7830 - 36ms/epoch - 994us/step\n",
      "Epoch 48/100\n",
      "36/36 - 0s - loss: 0.3394 - accuracy: 0.8198 - val_loss: 0.3686 - val_accuracy: 0.7964 - 36ms/epoch - 1000us/step\n",
      "Epoch 49/100\n",
      "36/36 - 0s - loss: 0.3405 - accuracy: 0.8150 - val_loss: 0.3718 - val_accuracy: 0.7852 - 35ms/epoch - 982us/step\n",
      "Epoch 50/100\n",
      "36/36 - 0s - loss: 0.3406 - accuracy: 0.8150 - val_loss: 0.3658 - val_accuracy: 0.7987 - 36ms/epoch - 999us/step\n",
      "Epoch 51/100\n",
      "36/36 - 0s - loss: 0.3399 - accuracy: 0.8117 - val_loss: 0.3767 - val_accuracy: 0.7897 - 36ms/epoch - 991us/step\n",
      "Epoch 52/100\n",
      "36/36 - 0s - loss: 0.3388 - accuracy: 0.8192 - val_loss: 0.3712 - val_accuracy: 0.7830 - 37ms/epoch - 1ms/step\n",
      "Epoch 53/100\n",
      "36/36 - 0s - loss: 0.3371 - accuracy: 0.8189 - val_loss: 0.3788 - val_accuracy: 0.7942 - 37ms/epoch - 1ms/step\n",
      "Epoch 54/100\n",
      "36/36 - 0s - loss: 0.3369 - accuracy: 0.8212 - val_loss: 0.3650 - val_accuracy: 0.7942 - 36ms/epoch - 992us/step\n",
      "Epoch 55/100\n",
      "36/36 - 0s - loss: 0.3385 - accuracy: 0.8209 - val_loss: 0.3765 - val_accuracy: 0.7987 - 35ms/epoch - 969us/step\n",
      "Epoch 56/100\n",
      "36/36 - 0s - loss: 0.3354 - accuracy: 0.8181 - val_loss: 0.3666 - val_accuracy: 0.7942 - 36ms/epoch - 1ms/step\n",
      "Epoch 57/100\n",
      "36/36 - 0s - loss: 0.3347 - accuracy: 0.8198 - val_loss: 0.3832 - val_accuracy: 0.7942 - 35ms/epoch - 977us/step\n",
      "Epoch 58/100\n",
      "36/36 - 0s - loss: 0.3364 - accuracy: 0.8201 - val_loss: 0.3764 - val_accuracy: 0.7897 - 35ms/epoch - 973us/step\n",
      "Epoch 59/100\n",
      "36/36 - 0s - loss: 0.3369 - accuracy: 0.8164 - val_loss: 0.3755 - val_accuracy: 0.7875 - 35ms/epoch - 984us/step\n",
      "Epoch 60/100\n",
      "36/36 - 0s - loss: 0.3386 - accuracy: 0.8181 - val_loss: 0.3685 - val_accuracy: 0.7987 - 35ms/epoch - 979us/step\n",
      "Epoch 61/100\n",
      "36/36 - 0s - loss: 0.3369 - accuracy: 0.8153 - val_loss: 0.3756 - val_accuracy: 0.7897 - 35ms/epoch - 973us/step\n",
      "Epoch 62/100\n",
      "36/36 - 0s - loss: 0.3354 - accuracy: 0.8195 - val_loss: 0.3734 - val_accuracy: 0.7875 - 35ms/epoch - 973us/step\n",
      "Epoch 63/100\n",
      "36/36 - 0s - loss: 0.3378 - accuracy: 0.8161 - val_loss: 0.3639 - val_accuracy: 0.7919 - 35ms/epoch - 964us/step\n",
      "Epoch 64/100\n",
      "36/36 - 0s - loss: 0.3392 - accuracy: 0.8156 - val_loss: 0.3727 - val_accuracy: 0.7897 - 35ms/epoch - 974us/step\n",
      "Epoch 65/100\n",
      "36/36 - 0s - loss: 0.3375 - accuracy: 0.8189 - val_loss: 0.3634 - val_accuracy: 0.7964 - 35ms/epoch - 974us/step\n",
      "Epoch 66/100\n",
      "36/36 - 0s - loss: 0.3375 - accuracy: 0.8170 - val_loss: 0.3852 - val_accuracy: 0.7897 - 36ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      "36/36 - 0s - loss: 0.3341 - accuracy: 0.8175 - val_loss: 0.3648 - val_accuracy: 0.8031 - 36ms/epoch - 990us/step\n",
      "Epoch 68/100\n",
      "36/36 - 0s - loss: 0.3325 - accuracy: 0.8217 - val_loss: 0.3697 - val_accuracy: 0.7964 - 34ms/epoch - 940us/step\n",
      "Epoch 69/100\n",
      "36/36 - 0s - loss: 0.3334 - accuracy: 0.8217 - val_loss: 0.3696 - val_accuracy: 0.7897 - 34ms/epoch - 946us/step\n",
      "Epoch 70/100\n",
      "36/36 - 0s - loss: 0.3354 - accuracy: 0.8223 - val_loss: 0.3626 - val_accuracy: 0.7830 - 34ms/epoch - 946us/step\n",
      "Epoch 71/100\n",
      "36/36 - 0s - loss: 0.3362 - accuracy: 0.8170 - val_loss: 0.3684 - val_accuracy: 0.8009 - 34ms/epoch - 935us/step\n",
      "Epoch 72/100\n",
      "36/36 - 0s - loss: 0.3334 - accuracy: 0.8209 - val_loss: 0.3636 - val_accuracy: 0.7919 - 33ms/epoch - 926us/step\n",
      "Epoch 73/100\n",
      "36/36 - 0s - loss: 0.3411 - accuracy: 0.8164 - val_loss: 0.3910 - val_accuracy: 0.7830 - 34ms/epoch - 938us/step\n",
      "Epoch 74/100\n",
      "36/36 - 0s - loss: 0.3382 - accuracy: 0.8156 - val_loss: 0.3703 - val_accuracy: 0.7897 - 34ms/epoch - 941us/step\n",
      "Epoch 75/100\n",
      "36/36 - 0s - loss: 0.3341 - accuracy: 0.8195 - val_loss: 0.3777 - val_accuracy: 0.7897 - 34ms/epoch - 955us/step\n",
      "Epoch 76/100\n",
      "36/36 - 0s - loss: 0.3344 - accuracy: 0.8212 - val_loss: 0.3643 - val_accuracy: 0.7987 - 34ms/epoch - 943us/step\n",
      "Epoch 77/100\n",
      "36/36 - 0s - loss: 0.3356 - accuracy: 0.8215 - val_loss: 0.3680 - val_accuracy: 0.7987 - 34ms/epoch - 945us/step\n",
      "Epoch 78/100\n",
      "36/36 - 0s - loss: 0.3327 - accuracy: 0.8209 - val_loss: 0.3759 - val_accuracy: 0.7852 - 34ms/epoch - 936us/step\n",
      "Epoch 79/100\n",
      "36/36 - 0s - loss: 0.3332 - accuracy: 0.8203 - val_loss: 0.3689 - val_accuracy: 0.7919 - 34ms/epoch - 951us/step\n",
      "Epoch 80/100\n",
      "36/36 - 0s - loss: 0.3327 - accuracy: 0.8223 - val_loss: 0.3791 - val_accuracy: 0.7919 - 34ms/epoch - 944us/step\n",
      "Epoch 81/100\n",
      "36/36 - 0s - loss: 0.3324 - accuracy: 0.8189 - val_loss: 0.3749 - val_accuracy: 0.7942 - 35ms/epoch - 958us/step\n",
      "Epoch 82/100\n",
      "36/36 - 0s - loss: 0.3349 - accuracy: 0.8209 - val_loss: 0.3856 - val_accuracy: 0.7852 - 34ms/epoch - 948us/step\n",
      "Epoch 83/100\n",
      "36/36 - 0s - loss: 0.3335 - accuracy: 0.8223 - val_loss: 0.3989 - val_accuracy: 0.8031 - 37ms/epoch - 1ms/step\n",
      "Epoch 84/100\n",
      "36/36 - 0s - loss: 0.3360 - accuracy: 0.8189 - val_loss: 0.3694 - val_accuracy: 0.7964 - 35ms/epoch - 974us/step\n",
      "Epoch 85/100\n",
      "36/36 - 0s - loss: 0.3329 - accuracy: 0.8217 - val_loss: 0.3731 - val_accuracy: 0.7964 - 34ms/epoch - 953us/step\n",
      "Epoch 86/100\n",
      "36/36 - 0s - loss: 0.3331 - accuracy: 0.8220 - val_loss: 0.3862 - val_accuracy: 0.8009 - 35ms/epoch - 970us/step\n",
      "Epoch 87/100\n",
      "36/36 - 0s - loss: 0.3325 - accuracy: 0.8212 - val_loss: 0.3801 - val_accuracy: 0.7897 - 38ms/epoch - 1ms/step\n",
      "Epoch 88/100\n",
      "36/36 - 0s - loss: 0.3343 - accuracy: 0.8223 - val_loss: 0.3745 - val_accuracy: 0.7919 - 39ms/epoch - 1ms/step\n",
      "Epoch 89/100\n",
      "36/36 - 0s - loss: 0.3338 - accuracy: 0.8209 - val_loss: 0.3591 - val_accuracy: 0.7942 - 38ms/epoch - 1ms/step\n",
      "Epoch 90/100\n",
      "36/36 - 0s - loss: 0.3319 - accuracy: 0.8206 - val_loss: 0.3938 - val_accuracy: 0.7964 - 36ms/epoch - 998us/step\n",
      "Epoch 91/100\n",
      "36/36 - 0s - loss: 0.3336 - accuracy: 0.8231 - val_loss: 0.3717 - val_accuracy: 0.7942 - 37ms/epoch - 1ms/step\n",
      "Epoch 92/100\n",
      "36/36 - 0s - loss: 0.3366 - accuracy: 0.8187 - val_loss: 0.3808 - val_accuracy: 0.7987 - 36ms/epoch - 998us/step\n",
      "Epoch 93/100\n",
      "36/36 - 0s - loss: 0.3328 - accuracy: 0.8189 - val_loss: 0.3837 - val_accuracy: 0.7875 - 36ms/epoch - 995us/step\n",
      "Epoch 94/100\n",
      "36/36 - 0s - loss: 0.3322 - accuracy: 0.8212 - val_loss: 0.3714 - val_accuracy: 0.7919 - 38ms/epoch - 1ms/step\n",
      "Epoch 95/100\n",
      "36/36 - 0s - loss: 0.3329 - accuracy: 0.8234 - val_loss: 0.3802 - val_accuracy: 0.7987 - 37ms/epoch - 1ms/step\n",
      "Epoch 96/100\n",
      "36/36 - 0s - loss: 0.3333 - accuracy: 0.8201 - val_loss: 0.3705 - val_accuracy: 0.7987 - 37ms/epoch - 1ms/step\n",
      "Epoch 97/100\n",
      "36/36 - 0s - loss: 0.3301 - accuracy: 0.8201 - val_loss: 0.3904 - val_accuracy: 0.7875 - 36ms/epoch - 1000us/step\n",
      "Epoch 98/100\n",
      "36/36 - 0s - loss: 0.3317 - accuracy: 0.8223 - val_loss: 0.3661 - val_accuracy: 0.7942 - 36ms/epoch - 996us/step\n",
      "Epoch 99/100\n",
      "36/36 - 0s - loss: 0.3354 - accuracy: 0.8226 - val_loss: 0.3735 - val_accuracy: 0.7964 - 35ms/epoch - 968us/step\n",
      "Epoch 100/100\n",
      "36/36 - 0s - loss: 0.3347 - accuracy: 0.8198 - val_loss: 0.3682 - val_accuracy: 0.7852 - 36ms/epoch - 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd050075ab0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 10\n",
    "output_size = 2\n",
    "hidden_layer_size = 50\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "    tf.keras.layers.Dense(output_size, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "batch_size = 100\n",
    "max_epochs = 100\n",
    "\n",
    "#early_stopping = tf.keras.callbacks.EarlyStopping()\n",
    "\n",
    "model.fit(train_inputs,\n",
    "         train_targets,\n",
    "         batch_size = batch_size,\n",
    "         epochs = max_epochs,\n",
    "        #callbacks= [early_stopping],\n",
    "         validation_data = (validation_inputs, validation_targets),\n",
    "         verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a61649c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07b5344e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 858us/step - loss: 0.3823 - accuracy: 0.7746\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy= model.evaluate(test_inputs, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a7080f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
